{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8941a278",
   "metadata": {},
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\"\n",
    "    style=\"padding-right:10px;width:140px;float:left\">\n",
    "<h2 style=\"white-space: nowrap\">Neural Signal and Signal Processing (NX-421)</h2>\n",
    "<hr style=\"clear:both\">\n",
    "<h1 style=\"colr:black\">Miniproject 2 - Processing and analysis of EMG data</h1>\n",
    "<h1 style=\"colr:black\">Part 2</h1>\n",
    "<h4 style=\"white-space: nowrap\">Camille Dorster, Toufan Kashaev, Johan Bordet</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95356d5f",
   "metadata": {},
   "source": [
    "## 1. Visualize & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedec3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_name = \"Data\"\n",
    "subject_folders = sorted([folder for folder in os.listdir(data_folder_name) if folder != \"s2\"])\n",
    "subject_files = []\n",
    "\n",
    "mov_mean_length = 25\n",
    "mov_mean_weights = np.ones(mov_mean_length) / mov_mean_length\n",
    "\n",
    "subjects = {}\n",
    "\n",
    "for folder in subject_folders:\n",
    "    folder_path = os.path.join(data_folder_name, folder)\n",
    "\n",
    "    # Find all *_E1.mat files in this subject folder\n",
    "    mat_files = [\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith('e1.mat')\n",
    "    ]\n",
    "\n",
    "    if not mat_files:\n",
    "        print(f\"No E1 file found in {folder_path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Assuming exactly one E1 file per subject; take the first\n",
    "    mat_file = mat_files[0]\n",
    "    path = os.path.join(folder_path, mat_file)\n",
    "\n",
    "    data = loadmat(path)\n",
    "\n",
    "    print('\\nSubject folder:', folder)\n",
    "    print('File:', mat_file)\n",
    "    print('Dataset variables:')\n",
    "    for key in data.keys():\n",
    "        if not key.startswith('__'):\n",
    "            print(' ', key)\n",
    "\n",
    "    # variables named as in your notebook\n",
    "    emg = data['emg']                          # shape: (T, n_channels)\n",
    "    stimulus = data['restimulus'].ravel()      # corrected labels (1D)\n",
    "    repetition = data['rerepetition'].ravel()  # corrected repetition indices (1D)\n",
    "\n",
    "    print(f\"EMG data dimension : {emg.shape}\")\n",
    "    print(f\"EMG data type : {type(emg)}\")\n",
    "\n",
    "    # number of movements and repetitions (excluding label 0 = rest)\n",
    "    n_stimuli = len(np.unique(stimulus)) - 1\n",
    "    n_repetitions = len(np.unique(repetition)) - 1\n",
    "\n",
    "    emg_windows = [[None for _ in range(n_repetitions)] for _ in range(n_stimuli)]\n",
    "    emg_envelopes = [[None for _ in range(n_repetitions)] for _ in range(n_stimuli)]\n",
    "\n",
    "    for stimuli_idx in range(n_stimuli):\n",
    "        for repetition_idx in range(n_repetitions):\n",
    "            idx = np.logical_and(\n",
    "                stimulus == (stimuli_idx + 1),\n",
    "                repetition == (repetition_idx + 1)\n",
    "            )\n",
    "\n",
    "            if not np.any(idx):\n",
    "                continue  # no samples for this (movement, repetition) pair\n",
    "\n",
    "            window = emg[idx, :]\n",
    "\n",
    "            # (optional) you could call a preprocessing here (e.g., filtered & rectified)\n",
    "            # window = preprocess_emg(window, fs)  # if you define such a function\n",
    "\n",
    "            emg_windows[stimuli_idx][repetition_idx] = window\n",
    "            emg_envelopes[stimuli_idx][repetition_idx] = convolve1d(\n",
    "                window,\n",
    "                mov_mean_weights,\n",
    "                axis=0,\n",
    "                mode=\"nearest\"\n",
    "            )\n",
    "\n",
    "    # store everything\n",
    "    subjects[folder] = {\n",
    "        'emg': emg,\n",
    "        'stimulus': stimulus,\n",
    "        'repetition': repetition,\n",
    "        'emg_windows': emg_windows,\n",
    "        'emg_envelopes': emg_envelopes,\n",
    "        'n_stimuli': n_stimuli,\n",
    "        'n_repetitions': n_repetitions,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot first EMG channel for all 27 subjects\n",
    "plt.close('all')\n",
    "fig, axes = plt.subplots(len(subjects), 1, figsize=(12, 2*len(subjects)))\n",
    "\n",
    "for idx, (fname, sub) in enumerate(subjects.items()):\n",
    "    emg = sub['emg']\n",
    "    EMG_channel = 5 if emg.shape[1] > 5 else 0\n",
    "    axes[idx].plot(emg[:, EMG_channel])\n",
    "    axes[idx].set_title(f\"EMG signal channel {EMG_channel} ({fname})\")\n",
    "    axes[idx].set_xlabel('Data points')\n",
    "    axes[idx].set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be32af",
   "metadata": {},
   "source": [
    "## 2. Feature extraction & visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea913d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (same lambdas as notebook)\n",
    "mav = lambda x: np.mean(np.abs(x), axis=0)\n",
    "std = lambda x: np.std(x, axis=0)\n",
    "maxav = lambda x: np.max(np.abs(x), axis=0)\n",
    "rms = lambda x: np.sqrt(np.mean(x**2, axis=0))\n",
    "wl = lambda x: np.sum(np.abs(np.diff(x, axis=0)), axis=0)\n",
    "ssc = lambda x: np.sum((np.diff(x, axis=0)[:-1, :] * np.diff(x, axis=0)[1:, :]) < 0, axis=0)\n",
    "\n",
    "# Choose features (default to the two used in the notebook)\n",
    "features = [mav, std]\n",
    "\n",
    "# Build dataset and labels per subject using the same function\n",
    "subject_datasets = {}\n",
    "for fname, sub in subjects.items():\n",
    "    print('Building dataset for', fname)\n",
    "    dataset, labels = build_dataset_from_ninapro(\n",
    "        emg=sub['emg'],\n",
    "        stimulus=sub['stimulus'],\n",
    "        repetition=sub['repetition'],\n",
    "        features=features\n",
    "    )\n",
    "    print(f\"  dataset shape: {dataset.shape}, labels shape: {labels.shape}\")\n",
    "    subject_datasets[fname] = {'dataset': dataset, 'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13053b9c",
   "metadata": {},
   "source": [
    "## 4. Gradient boosting classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a baseline model per subject\n",
    "\n",
    "results = []\n",
    "\n",
    "for fname, data_pair in subject_datasets.items():\n",
    "    X = data_pair['dataset']\n",
    "    y = data_pair['labels']\n",
    "    print('\\nTraining subject:', fname)\n",
    "    # train/val/test split as in notebook\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.4, stratify=y, random_state=0\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=0\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_z = scaler.fit_transform(X_train)\n",
    "    X_val_z = scaler.transform(X_val)\n",
    "    X_test_z = scaler.transform(X_test)\n",
    "\n",
    "    gb = GradientBoostingClassifier(random_state=0)\n",
    "    gb.fit(X_train_z, y_train)\n",
    "\n",
    "    y_val_pred = gb.predict(X_val_z)\n",
    "    print('  Baseline val accuracy:', accuracy_score(y_val, y_val_pred))\n",
    "    print('  Baseline val macro-F1:', f1_score(y_val, y_val_pred, average='macro'))\n",
    "\n",
    "    y_test_pred = gb.predict(X_test_z)\n",
    "    baseline_acc = accuracy_score(y_test, y_test_pred)\n",
    "    baseline_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "    print('  Test accuracy:', baseline_acc)\n",
    "    print('  Test macro-F1:', baseline_f1)\n",
    "\n",
    "    # Collect results\n",
    "    results.append({\n",
    "        'subject_file': fname,\n",
    "        'baseline_acc': float(baseline_acc),\n",
    "        'baseline_f1': float(baseline_f1),\n",
    "    })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NX-421",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
